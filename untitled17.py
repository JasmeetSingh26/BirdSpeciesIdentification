# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1stIW5ozCEPo6sB24AWBLpYv6zL7BaXkv
"""

! pip install -q kaggle

from google.colab import files

files.upload()

! mkdir ~/.kaggle

!cp /content/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions list

!kaggle datasets download soumendraprasad/sound-of-114-species-of-birds-till-2022

!unzip /content/sound-of-114-species-of-birds-till-2022.zip

# -*- coding: utf-8 -*-
"""
Bird Sound Classification: FAST OPTIMIZED VERSION
"""

import os
import json
import librosa
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import LabelEncoder
from tqdm import tqdm
import matplotlib.pyplot as plt
import pandas as pd

# ---------------------------
# 1. FAST Feature Extraction
# ---------------------------

def extract_features_fast(audio_file, n_mfcc=40, n_mels=128, max_time_steps=1000, hop_length=512):
    """
    Extract both MFCC and LogMel in one pass - MUCH FASTER!
    """
    try:
        # Load audio once
        y, sr = librosa.load(audio_file, sr=22050, duration=30)  # Limit to 30 seconds max

        # MFCC extraction (averaged)
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)
        mfcc_mean = np.mean(mfcc, axis=1)  # Average over time
        mfcc_feat = np.expand_dims(mfcc_mean, axis=(0,2))  # (1, n_mfcc, 1)

        # LogMel extraction (with fixed time dimension)
        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)
        log_mel = librosa.power_to_db(mel_spec)

        # Fix time dimension efficiently
        current_time = log_mel.shape[1]
        if current_time < max_time_steps:
            # Pad
            log_mel = np.pad(log_mel, ((0, 0), (0, max_time_steps - current_time)),
                           mode='constant', constant_values=-80)  # Use -80 dB as silence
        else:
            # Truncate from center (keep most important part)
            start = (current_time - max_time_steps) // 2
            log_mel = log_mel[:, start:start + max_time_steps]

        logmel_feat = log_mel[np.newaxis, ..., np.newaxis]  # (1, n_mels, max_time_steps, 1)

        return mfcc_feat[0], logmel_feat[0], True  # Remove batch dim, return success flag

    except Exception as e:
        print(f"Error processing {audio_file}: {e}")
        # Return dummy features on error
        mfcc_dummy = np.zeros((n_mfcc, 1))
        logmel_dummy = np.zeros((n_mels, max_time_steps, 1))
        return mfcc_dummy, logmel_dummy, False

# ---------------------------
# 2. FAST Dataset Preparation
# ---------------------------

audio_dir = '/content/Voice of Birds/Voice of Birds'
MAX_TIME_STEPS = 1000  # Set this manually - much faster than dynamic calculation

print("Fast processing with fixed time steps...")
extracted_features_mfcc = []
extracted_features_logmel = []
failed_files = 0

# Count total files
total_files = sum(len(files) for _, _, files in os.walk(audio_dir))
print(f"Processing {total_files} files...")

with tqdm(total=total_files, desc='Processing files') as pbar:
    for target_class in os.listdir(audio_dir):
        class_path = os.path.join(audio_dir, target_class)
        if not os.path.isdir(class_path):
            continue

        for audio_file in os.listdir(class_path):
            if not audio_file.lower().endswith(('.wav', '.mp3', '.flac', '.m4a')):
                pbar.update(1)
                continue

            audio_path = os.path.join(class_path, audio_file)

            # Extract both features in one call
            mfcc_feat, logmel_feat, success = extract_features_fast(
                audio_path, max_time_steps=MAX_TIME_STEPS
            )

            if success:
                extracted_features_mfcc.append([mfcc_feat, target_class])
                extracted_features_logmel.append([logmel_feat, target_class])
            else:
                failed_files += 1

            pbar.update(1)

print(f"Successfully processed: {len(extracted_features_mfcc)} files")
print(f"Failed files: {failed_files}")

# Convert to DataFrame
df_mfcc = pd.DataFrame(extracted_features_mfcc, columns=['features', 'class'])
df_logmel = pd.DataFrame(extracted_features_logmel, columns=['features', 'class'])

# Encode labels
le = LabelEncoder()
df_mfcc['target'] = le.fit_transform(df_mfcc['class'])
df_logmel['target'] = le.transform(df_logmel['class'])

# Save mapping
prediction_dict = dict(zip(range(len(le.classes_)), le.classes_))
with open('/content/prediction.json', 'w') as f:
    json.dump(prediction_dict, f)

print(f"Classes found: {le.classes_}")
print(f"Number of classes: {len(le.classes_)}")

# Convert to numpy arrays - FAST VERSION
print("Converting to numpy arrays...")
X_mfcc = np.array([feat for feat in df_mfcc['features']])
y_mfcc = df_mfcc['target'].values

X_logmel = np.array([feat for feat in df_logmel['features']])
y_logmel = df_logmel['target'].values

print(f"MFCC shape: {X_mfcc.shape}")
print(f"LogMel shape: {X_logmel.shape}")

# Verify shapes
assert X_mfcc.shape[0] == X_logmel.shape[0], "Mismatch in number of samples"
print("âœ… Shape verification passed!")

# Train/Val/Test split
def split_dataset(X, y, train_ratio=0.8, val_ratio=0.1, random_state=42):
    np.random.seed(random_state)  # For reproducibility
    total = len(X)
    idx = np.arange(total)
    np.random.shuffle(idx)
    X, y = X[idx], y[idx]
    train_end = int(total*train_ratio)
    val_end = train_end + int(total*val_ratio)
    return (X[:train_end], y[:train_end]), (X[train_end:val_end], y[train_end:val_end]), (X[val_end:], y[val_end:])

print("Splitting datasets...")
(X_train_mfcc, y_train_mfcc), (X_val_mfcc, y_val_mfcc), (X_test_mfcc, y_test_mfcc) = split_dataset(X_mfcc, y_mfcc)
(X_train_logmel, y_train_logmel), (X_val_logmel, y_val_logmel), (X_test_logmel, y_test_logmel) = split_dataset(X_logmel, y_logmel)

print(f"Training samples: {len(X_train_mfcc)}")
print(f"Validation samples: {len(X_val_mfcc)}")
print(f"Test samples: {len(X_test_mfcc)}")

target_classes = len(le.classes_)

# --- Model A: Conv1D on MFCC ---
def build_model_A(input_shape=(40,1), target_classes=target_classes):
    model = keras.Sequential([
        keras.layers.Input(shape=input_shape),
        keras.layers.Conv1D(128, 3, activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPool1D(2, padding='same'),
        keras.layers.Conv1D(256, 3, activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPool1D(2, padding='same'),
        keras.layers.Conv1D(256, 3, activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPool1D(2, padding='same'),
        keras.layers.Flatten(),
        keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.L2(1e-2)),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.L2(1e-2)),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(target_classes, activation='softmax')
    ])
    return model

# --- Model B: 2D CNN Log-Mel (FIXED INPUT SHAPE) ---
def build_model_B(input_shape, target_classes=target_classes):
    model = keras.Sequential([
        keras.layers.Input(shape=input_shape),
        keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPool2D((2,2)),
        keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPool2D((2,2)),
        keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPool2D((2,2)),
        keras.layers.Flatten(),
        keras.layers.Dense(512, activation='relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(target_classes, activation='softmax')
    ])
    return model

# --- Model C: CRNN Log-Mel (FIXED INPUT SHAPE) ---
def build_model_C(input_shape, target_classes=target_classes):
    inputs = keras.Input(shape=input_shape)
    x = keras.layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)
    x = keras.layers.MaxPool2D((2,2))(x)
    x = keras.layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)
    x = keras.layers.MaxPool2D((2,2))(x)

    # Reshape for RNN: (batch, time, features)
    new_shape = (x.shape[2], x.shape[1] * x.shape[3])
    x = keras.layers.Reshape(new_shape)(x)
    x = keras.layers.GRU(128, return_sequences=False)(x)
    x = keras.layers.Dense(512, activation='relu')(x)
    x = keras.layers.Dropout(0.3)(x)
    outputs = keras.layers.Dense(target_classes, activation='softmax')(x)
    return keras.Model(inputs, outputs)

print("Models ready to train!")
print(f"Training data shapes:")
print(f"MFCC: {X_train_mfcc.shape}")
print(f"LogMel: {X_train_logmel.shape}")


# ---------------------------
# 4. Compile & Train Models
# ---------------------------

# # Model A
# model_A = build_model_A(input_shape=X_train_mfcc.shape[1:])
# model_A.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# history_A = model_A.fit(X_train_mfcc, y_train_mfcc,
#                         validation_data=(X_val_mfcc, y_val_mfcc),
#                         epochs=100, batch_size=32)

# Model B
model_B = build_model_B(input_shape=X_train_logmel.shape[1:])
model_B.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history_B = model_B.fit(X_train_logmel, y_train_logmel,
                        validation_data=(X_val_logmel, y_val_logmel),
                        epochs=50, batch_size=32)

# Model C
model_C = build_model_C(input_shape=X_train_logmel.shape[1:])
model_C.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history_C = model_C.fit(X_train_logmel, y_train_logmel,
                        validation_data=(X_val_logmel, y_val_logmel),
                        epochs=50, batch_size=32)

# Save models
# model_A.save('/content/model_A.h5')
model_B.save('/content/model_B.h5')
model_C.save('/content/model_C.h5')

# ---------------------------
# 5. Ensemble Prediction (Soft Voting)
# ---------------------------

def test_on_split(X_test_mfcc, X_test_logmel, y_test, prediction_dict):
    """
    Test the ensemble model on the test split and evaluate performance.
    """
    # Load the models
    model_A = tf.keras.models.load_model('/content/model_A.h5')
    model_B = tf.keras.models.load_model('/content/model_B.h5')
    model_C = tf.keras.models.load_model('/content/model_C.h5')

    model_A.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    model_B.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    model_C.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    print("Loaded models successfully. Starting predictions...")

    y_pred = []
    confidence_scores = []

    for i in range(len(X_test_mfcc)):
        # Prepare features for prediction
        mfcc_feat = X_test_mfcc[i][np.newaxis, ...]  # Add batch dimension
        logmel_feat = X_test_logmel[i][np.newaxis, ...]  # Add batch dimension

        # Predict with all models
        pred_A = model_A.predict(mfcc_feat)
        pred_B = model_B.predict(logmel_feat)
        pred_C = model_C.predict(logmel_feat)

        # Ensemble soft voting
        soft_vote = (pred_A + pred_B + pred_C) / 3.0
        target_label = np.argmax(soft_vote)
        y_pred.append(target_label)

        confidence = round(np.max(soft_vote) * 100, 2)
        confidence_scores.append(confidence)

        # Print progress for every 10 samples
        if i % 10 == 0:
            print(f"Processed {i}/{len(X_test_mfcc)} samples. Current prediction: {prediction_dict[str(target_label)]} with confidence {confidence}%")

    # Evaluate accuracy
    accuracy = np.mean(np.array(y_pred) == np.array(y_test))
    print(f"Test Accuracy: {accuracy * 100:.2f}%")

    return y_pred, confidence_scores, accuracy

# Load the prediction dictionary
with open('/content/prediction.json', 'r') as f:
    prediction_dict = json.load(f)

# Test the ensemble model on the test split
y_pred, confidence_scores, test_accuracy = test_on_split(X_test_mfcc, X_test_logmel, y_test_mfcc, prediction_dict)

# Print final results
print(f"Final Test Accuracy: {test_accuracy * 100:.2f}%")

